{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syed.nusrath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../news_classification_engine/dataset.csv', encoding=\"ISO-8859-1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_text = data[['news']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "news     Mobiles rack up 20 years of use\\n \\n Mobile ph...\n",
      "index                                                 2210\n",
      "Name: 2210, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents.loc[2210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preview preprocessing on selected document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Mobiles', 'rack', 'up', '20', 'years', 'of', 'use\\n', '\\n', 'Mobile', 'phones', 'in', 'the', 'UK', 'are', 'celebrating', 'their', '20th', 'anniversary', 'this', 'weekend.\\n', '\\n', \"Britain's\", 'first', 'mobile', 'phone', 'call', 'was', 'made', 'across', 'the', 'Vodafone', 'network', 'on', '1', 'January', '1985', 'by', 'veteran', 'comedian', 'Ernie', 'Wise.', 'In', 'the', '20', 'years', 'since', 'that', 'day,', 'mobile', 'phones', 'have', 'become', 'an', 'integral', 'part', 'of', 'modern', 'life', 'and', 'now', 'almost', '90%', 'of', 'Britons', 'own', 'a', 'handset.', 'Mobiles', 'have', 'become', 'so', 'popular', 'that', 'many', 'people', 'use', 'their', 'handset', 'as', 'their', 'only', 'phone', 'and', 'rarely', 'use', 'a', 'landline.\\n', '\\n', 'The', 'first', 'ever', 'call', 'over', 'a', 'portable', 'phone', 'was', 'made', 'in', '1973', 'in', 'New', 'York', 'but', 'it', 'took', '10', 'years', 'for', 'the', 'first', 'commercial', 'mobile', 'service', 'to', 'be', 'launched.', 'The', 'UK', 'was', 'not', 'far', 'behind', 'the', 'rest', 'of', 'the', 'world', 'in', 'setting', 'up', 'networks', 'in', '1985', 'that', 'let', 'people', 'make', 'calls', 'while', 'they', 'walked.', 'The', 'first', 'call', 'was', 'made', 'from', 'St', \"Katherine's\", 'dock', 'to', \"Vodafone's\", 'head', 'office', 'in', 'Newbury', 'which', 'at', 'the', 'time', 'was', 'over', 'a', 'curry', 'house.', 'For', 'the', 'first', 'nine', 'days', 'of', '1985', 'Vodafone', 'was', 'the', 'only', 'firm', 'with', 'a', 'mobile', 'network', 'in', 'the', 'UK.', 'Then', 'on', '10', 'January', 'Cellnet', '(now', 'O2)', 'launched', 'its', 'service.', 'Mike', 'Caudwell,', 'spokesman', 'for', 'Vodafone,', 'said', 'that', 'when', 'phones', 'were', 'launched', 'they', 'were', 'the', 'size', 'of', 'a', 'briefcase,', 'cost', 'about', 'Â£2,000', 'and', 'had', 'a', 'battery', 'life', 'of', 'little', 'more', 'than', '20', 'minutes.\\n', '\\n', '\"Despite', 'that', 'they', 'were', 'hugely', 'popular', 'in', 'the', 'mid-80s,\"', 'he', 'said.', '\"They', 'became', 'a', 'yuppy', 'must-have', 'and', 'a', 'status', 'symbol', 'among', 'young', 'wealthy', 'business', 'folk.\"', 'This', 'was', 'also', 'despite', 'the', 'fact', 'that', 'the', 'phones', 'used', 'analogue', 'radio', 'signals', 'to', 'communicate', 'which', 'made', 'them', 'very', 'easy', 'to', 'eavesdrop', 'on.', 'He', 'said', 'it', 'took', 'Vodafone', 'almost', 'nine', 'years', 'to', 'rack', 'up', 'its', 'first', 'million', 'customers', 'but', 'only', '18', 'months', 'to', 'get', 'the', 'second', 'million.', '\"It\\'s', 'very', 'easy', 'to', 'forget', 'that', 'in', '1983', 'when', 'we', 'put', 'the', 'bid', 'document', 'in', 'we', 'were', 'forecasting', 'that', 'the', 'total', 'market', 'would', 'be', 'two', 'million', 'people,\"', 'he', 'said.', '\"Cellnet', 'was', 'forecasting', 'half', 'that.\"', 'Now', 'Vodafone', 'has', '14m', 'customers', 'in', 'the', 'UK', 'alone.', 'Cellnet', 'and', 'Vodafone', 'were', 'the', 'only', 'mobile', 'phone', 'operators', 'in', 'the', 'UK', 'until', '1993', 'when', 'One2One', '(now', 'T-Mobile)', 'was', 'launched.', 'Orange', 'had', 'its', 'UK', 'launch', 'in', '1994.', 'Both', 'newcomers', 'operated', 'digital', 'mobile', 'networks', 'and', 'now', 'all', 'operators', 'use', 'this', 'technology.', 'The', 'analogue', 'spectrum', 'for', 'the', 'old', 'phones', 'has', 'been', 'retired.', 'Called', 'Global', 'System', 'for', 'Mobiles', '(GSM)', 'this', 'is', 'now', 'the', 'most', 'widely', 'used', 'phone', 'technology', 'on', 'the', 'planet', 'and', 'is', 'used', 'to', 'help', 'more', 'than', '1.2', 'billion', 'people', 'make', 'calls.', 'Mr', 'Caudwell', 'said', 'the', 'advent', 'of', 'digital', 'technology', 'also', 'helped', 'to', 'introduce', 'all', 'those', 'things,', 'such', 'as', 'text', 'messaging', 'and', 'roaming', 'that', 'have', 'made', 'mobiles', 'so', 'popular.\\n']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['mobil', 'rack', 'year', 'mobil', 'phone', 'celebr', 'anniversari', 'weekend', 'britain', 'mobil', 'phone', 'vodafon', 'network', 'januari', 'veteran', 'comedian', 'erni', 'wise', 'year', 'mobil', 'phone', 'integr', 'modern', 'life', 'briton', 'handset', 'mobil', 'popular', 'peopl', 'handset', 'phone', 'rare', 'landlin', 'portabl', 'phone', 'york', 'take', 'year', 'commerci', 'mobil', 'servic', 'launch', 'rest', 'world', 'set', 'network', 'peopl', 'call', 'walk', 'katherin', 'dock', 'vodafon', 'head', 'offic', 'newburi', 'time', 'curri', 'hous', 'day', 'vodafon', 'firm', 'mobil', 'network', 'januari', 'cellnet', 'launch', 'servic', 'mike', 'caudwel', 'spokesman', 'vodafon', 'say', 'phone', 'launch', 'size', 'briefcas', 'cost', 'batteri', 'life', 'littl', 'minut', 'despit', 'huge', 'popular', 'say', 'yuppi', 'statu', 'symbol', 'young', 'wealthi', 'busi', 'folk', 'despit', 'fact', 'phone', 'analogu', 'radio', 'signal', 'commun', 'easi', 'eavesdrop', 'say', 'take', 'vodafon', 'year', 'rack', 'million', 'custom', 'month', 'second', 'million', 'easi', 'forget', 'document', 'forecast', 'total', 'market', 'million', 'peopl', 'say', 'cellnet', 'forecast', 'half', 'vodafon', 'custom', 'cellnet', 'vodafon', 'mobil', 'phone', 'oper', 'mobil', 'launch', 'orang', 'launch', 'newcom', 'oper', 'digit', 'mobil', 'network', 'oper', 'technolog', 'analogu', 'spectrum', 'phone', 'retir', 'call', 'global', 'mobil', 'wide', 'phone', 'technolog', 'planet', 'help', 'billion', 'peopl', 'call', 'caudwel', 'say', 'advent', 'digit', 'technolog', 'help', 'introduc', 'thing', 'text', 'messag', 'roam', 'mobil', 'popular']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 2210].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [china, role, yuko, split, china, lend, russia...\n",
       "1    [rebound, weather, effect, price, recov, asian...\n",
       "2    [indonesia, declin, debt, freez, indonesia, lo...\n",
       "3    [payoff, shell, boss, shell, financ, chief, st...\n",
       "4    [bank, settlement, bank, america, subsidiari, ...\n",
       "5    [verizon, seal, takeov, verizon, takeov, battl...\n",
       "6    [parmalat, boast, doubl, profit, parmalat, ita...\n",
       "7    [seek, smoker, rule, justic, depart, overturn,...\n",
       "8    [steel, firm, job, mittal, steel, world, large...\n",
       "9    [car, pull, retail, figur, retail, sale, fell,...\n",
       "Name: news, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['news'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words on the Data set\n",
    "Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abl\n",
      "1 accord\n",
      "2 agre\n",
      "3 ambit\n",
      "4 analyst\n",
      "5 announc\n",
      "6 aton\n",
      "7 attempt\n",
      "8 auction\n",
      "9 bank\n",
      "10 bankruptci\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "count = 0 # showing only 10 words\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim filter_extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out tokens that appear in\n",
    "\n",
    "    - less than 15 documents (absolute number) or\n",
    "    - more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "    - after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim doc2bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 1),\n",
       " (45, 1),\n",
       " (50, 2),\n",
       " (59, 1),\n",
       " (106, 1),\n",
       " (133, 1),\n",
       " (134, 2),\n",
       " (157, 1),\n",
       " (178, 1),\n",
       " (179, 1),\n",
       " (222, 3),\n",
       " (271, 2),\n",
       " (300, 1),\n",
       " (307, 1),\n",
       " (326, 1),\n",
       " (340, 1),\n",
       " (346, 3),\n",
       " (353, 1),\n",
       " (364, 1),\n",
       " (366, 1),\n",
       " (374, 1),\n",
       " (381, 1),\n",
       " (383, 1),\n",
       " (398, 12),\n",
       " (399, 1),\n",
       " (401, 4),\n",
       " (405, 10),\n",
       " (523, 1),\n",
       " (541, 1),\n",
       " (548, 3),\n",
       " (555, 1),\n",
       " (558, 3),\n",
       " (581, 1),\n",
       " (585, 1),\n",
       " (609, 2),\n",
       " (614, 2),\n",
       " (624, 2),\n",
       " (647, 2),\n",
       " (682, 1),\n",
       " (703, 3),\n",
       " (765, 1),\n",
       " (808, 4),\n",
       " (843, 2),\n",
       " (851, 2),\n",
       " (863, 1),\n",
       " (936, 1),\n",
       " (939, 1),\n",
       " (1018, 1),\n",
       " (1040, 1),\n",
       " (1062, 1),\n",
       " (1192, 5),\n",
       " (1213, 1),\n",
       " (1215, 1),\n",
       " (1367, 1),\n",
       " (1373, 1),\n",
       " (1398, 1),\n",
       " (1413, 1),\n",
       " (1448, 1),\n",
       " (1495, 1),\n",
       " (1589, 1),\n",
       " (1615, 1),\n",
       " (1616, 1),\n",
       " (1634, 1),\n",
       " (1718, 2),\n",
       " (1720, 1),\n",
       " (1790, 1),\n",
       " (1860, 1),\n",
       " (1911, 1),\n",
       " (1990, 1),\n",
       " (2037, 1),\n",
       " (2121, 1),\n",
       " (2151, 1),\n",
       " (2288, 7),\n",
       " (2343, 1),\n",
       " (2403, 1),\n",
       " (2462, 2),\n",
       " (2593, 1),\n",
       " (2610, 1),\n",
       " (2860, 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[2210]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview Bag Of Words for our sample preprocessed document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 39 (\"firm\") appears 1 time.\n",
      "Word 45 (\"global\") appears 1 time.\n",
      "Word 50 (\"help\") appears 2 time.\n",
      "Word 59 (\"littl\") appears 1 time.\n",
      "Word 106 (\"size\") appears 1 time.\n",
      "Word 133 (\"day\") appears 1 time.\n",
      "Word 134 (\"despit\") appears 2 time.\n",
      "Word 157 (\"market\") appears 1 time.\n",
      "Word 178 (\"world\") appears 1 time.\n",
      "Word 179 (\"york\") appears 1 time.\n",
      "Word 222 (\"oper\") appears 3 time.\n",
      "Word 271 (\"januari\") appears 2 time.\n",
      "Word 300 (\"time\") appears 1 time.\n",
      "Word 307 (\"busi\") appears 1 time.\n",
      "Word 326 (\"head\") appears 1 time.\n",
      "Word 340 (\"offic\") appears 1 time.\n",
      "Word 346 (\"popular\") appears 3 time.\n",
      "Word 353 (\"second\") appears 1 time.\n",
      "Word 364 (\"total\") appears 1 time.\n",
      "Word 366 (\"wide\") appears 1 time.\n",
      "Word 374 (\"billion\") appears 1 time.\n",
      "Word 381 (\"commun\") appears 1 time.\n",
      "Word 383 (\"cost\") appears 1 time.\n",
      "Word 398 (\"mobil\") appears 12 time.\n",
      "Word 399 (\"month\") appears 1 time.\n",
      "Word 401 (\"network\") appears 4 time.\n",
      "Word 405 (\"phone\") appears 10 time.\n",
      "Word 523 (\"young\") appears 1 time.\n",
      "Word 541 (\"huge\") appears 1 time.\n",
      "Word 548 (\"million\") appears 3 time.\n",
      "Word 555 (\"spokesman\") appears 1 time.\n",
      "Word 558 (\"technolog\") appears 3 time.\n",
      "Word 581 (\"half\") appears 1 time.\n",
      "Word 585 (\"hous\") appears 1 time.\n",
      "Word 609 (\"digit\") appears 2 time.\n",
      "Word 614 (\"forecast\") appears 2 time.\n",
      "Word 624 (\"servic\") appears 2 time.\n",
      "Word 647 (\"custom\") appears 2 time.\n",
      "Word 682 (\"rest\") appears 1 time.\n",
      "Word 703 (\"call\") appears 3 time.\n",
      "Word 765 (\"mike\") appears 1 time.\n",
      "Word 808 (\"peopl\") appears 4 time.\n",
      "Word 843 (\"life\") appears 2 time.\n",
      "Word 851 (\"take\") appears 2 time.\n",
      "Word 863 (\"fact\") appears 1 time.\n",
      "Word 936 (\"radio\") appears 1 time.\n",
      "Word 939 (\"set\") appears 1 time.\n",
      "Word 1018 (\"introduc\") appears 1 time.\n",
      "Word 1040 (\"rare\") appears 1 time.\n",
      "Word 1062 (\"minut\") appears 1 time.\n",
      "Word 1192 (\"launch\") appears 5 time.\n",
      "Word 1213 (\"retir\") appears 1 time.\n",
      "Word 1215 (\"signal\") appears 1 time.\n",
      "Word 1367 (\"document\") appears 1 time.\n",
      "Word 1373 (\"symbol\") appears 1 time.\n",
      "Word 1398 (\"messag\") appears 1 time.\n",
      "Word 1413 (\"batteri\") appears 1 time.\n",
      "Word 1448 (\"weekend\") appears 1 time.\n",
      "Word 1495 (\"celebr\") appears 1 time.\n",
      "Word 1589 (\"integr\") appears 1 time.\n",
      "Word 1615 (\"britain\") appears 1 time.\n",
      "Word 1616 (\"briton\") appears 1 time.\n",
      "Word 1634 (\"thing\") appears 1 time.\n",
      "Word 1718 (\"easi\") appears 2 time.\n",
      "Word 1720 (\"forget\") appears 1 time.\n",
      "Word 1790 (\"veteran\") appears 1 time.\n",
      "Word 1860 (\"wise\") appears 1 time.\n",
      "Word 1911 (\"commerci\") appears 1 time.\n",
      "Word 1990 (\"statu\") appears 1 time.\n",
      "Word 2037 (\"modern\") appears 1 time.\n",
      "Word 2121 (\"walk\") appears 1 time.\n",
      "Word 2151 (\"newcom\") appears 1 time.\n",
      "Word 2288 (\"vodafon\") appears 7 time.\n",
      "Word 2343 (\"orang\") appears 1 time.\n",
      "Word 2403 (\"text\") appears 1 time.\n",
      "Word 2462 (\"handset\") appears 2 time.\n",
      "Word 2593 (\"anniversari\") appears 1 time.\n",
      "Word 2610 (\"comedian\") appears 1 time.\n",
      "Word 2860 (\"portabl\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[2210]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "# from pprint import pprint\n",
    "# for doc in corpus_tfidf:\n",
    "#     pprint(doc)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=3, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"game\" + 0.006*\"peopl\" + 0.005*\"time\" + 0.005*\"compani\" + 0.005*\"play\" + 0.004*\"world\" + 0.004*\"firm\" + 0.004*\"player\" + 0.004*\"come\" + 0.004*\"think\"\n",
      "Topic: 1 \n",
      "Words: 0.007*\"peopl\" + 0.006*\"time\" + 0.005*\"mobil\" + 0.005*\"phone\" + 0.005*\"world\" + 0.004*\"servic\" + 0.004*\"like\" + 0.004*\"come\" + 0.004*\"work\" + 0.004*\"game\"\n",
      "Topic: 2 \n",
      "Words: 0.006*\"film\" + 0.005*\"peopl\" + 0.005*\"govern\" + 0.004*\"game\" + 0.004*\"time\" + 0.004*\"best\" + 0.004*\"go\" + 0.004*\"labour\" + 0.004*\"like\" + 0.004*\"plan\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=3, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Word: 0.004*\"elect\" + 0.004*\"labour\" + 0.004*\"parti\" + 0.003*\"tori\" + 0.003*\"blair\" + 0.003*\"brown\" + 0.003*\"govern\" + 0.003*\"howard\" + 0.002*\"minist\" + 0.002*\"plan\"\n",
      "Topic: 1 \n",
      "Word: 0.003*\"mobil\" + 0.003*\"phone\" + 0.002*\"peopl\" + 0.002*\"firm\" + 0.002*\"servic\" + 0.002*\"technolog\" + 0.002*\"music\" + 0.002*\"china\" + 0.002*\"user\" + 0.002*\"compani\"\n",
      "Topic: 2 \n",
      "Word: 0.005*\"film\" + 0.004*\"game\" + 0.003*\"award\" + 0.003*\"best\" + 0.003*\"play\" + 0.002*\"england\" + 0.002*\"star\" + 0.002*\"club\" + 0.002*\"player\" + 0.002*\"music\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(news    Mobiles rack up 20 years of use\\n \\n Mobile ph...\n",
       " type                                                 tech\n",
       " Name: 2210, dtype: object,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2210],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9943941235542297\t \n",
      "Topic: 0.007*\"peopl\" + 0.006*\"time\" + 0.005*\"mobil\" + 0.005*\"phone\" + 0.005*\"world\" + 0.004*\"servic\" + 0.004*\"like\" + 0.004*\"come\" + 0.004*\"work\" + 0.004*\"game\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[2210]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance evaluation by classifying sample document using LDA TF-IDF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9945883750915527\t \n",
      "Topic: 0.003*\"mobil\" + 0.003*\"phone\" + 0.002*\"peopl\" + 0.002*\"firm\" + 0.002*\"servic\" + 0.002*\"technolog\" + 0.002*\"music\" + 0.002*\"china\" + 0.002*\"user\" + 0.002*\"compani\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[2210]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unseen_document = '''\n",
    "Sydney gamer has been charged after he was heard allegedly assaulting a woman during a live stream of the hugely popular game Fortnite.\n",
    "\n",
    "The 26-year-old man who goes by the handle MrDeadMoth was arrested after someone saw the video and reported it to police.\n",
    "\n",
    "In the video, that went viral on social media, a woman can be heard screaming off-camera.\n",
    "\n",
    "Two children were inside the home at the time of the alleged assault.\n",
    "'''\n",
    "\n",
    "unseen_document = ' '.join(preprocess(unseen_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9724864363670349\t Topic: 0.007*\"peopl\" + 0.006*\"time\" + 0.005*\"mobil\" + 0.005*\"phone\" + 0.005*\"world\"\n",
      "Score: 0.014182060025632381\t Topic: 0.006*\"film\" + 0.005*\"peopl\" + 0.005*\"govern\" + 0.004*\"game\" + 0.004*\"time\"\n",
      "Score: 0.013331498019397259\t Topic: 0.007*\"game\" + 0.006*\"peopl\" + 0.005*\"time\" + 0.005*\"compani\" + 0.005*\"play\"\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Score: 0.6965793371200562\t Topic: 0.007*\"game\" + 0.006*\"peopl\" + 0.005*\"time\" + 0.005*\"compani\" + 0.005*\"play\"\n",
      "Score: 0.28790152072906494\t Topic: 0.007*\"peopl\" + 0.006*\"time\" + 0.005*\"mobil\" + 0.005*\"phone\" + 0.005*\"world\"\n",
      "Score: 0.015519153326749802\t Topic: 0.006*\"film\" + 0.005*\"peopl\" + 0.005*\"govern\" + 0.004*\"game\" + 0.004*\"time\"\n"
     ]
    }
   ],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))\n",
    "    \n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = processed_docs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs_vec = [' '.join(ele) for ele in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(processed_docs_vec)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer( max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(processed_docs_vec)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syed.nusrath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_topics = 3\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "say govern peopl labour year elect compani firm blair market\n",
      "Topic 1:\n",
      "game play england player match team say injuri final wale\n",
      "Topic 2:\n",
      "film award best star oscar nomin actor actress festiv director\n",
      "Topic 0:\n",
      "game say year play film time best player world award\n",
      "Topic 1:\n",
      "say govern elect labour peopl parti year minist plan tell\n",
      "Topic 2:\n",
      "say peopl year mobil technolog phone servic firm market user\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer.fit_transform([unseen_document])\n",
    "predict = lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
